// AI ì„œë¹„ìŠ¤ ê´€ë¦¬ì í´ë˜ìŠ¤

class AIServiceManager {
    constructor() {
        this.services = {
            claude: {
                name: 'Claude',
                baseUrl: 'https://api.anthropic.com/v1/messages',
                headers: {
                    'anthropic-version': '2023-06-01',
                    'content-type': 'application/json',
                }
            },
            gpt: {
                name: 'GPT',
                baseUrl: 'https://api.openai.com/v1/chat/completions',
                headers: {
                    'content-type': 'application/json',
                }
            },
            groq: {
                name: 'Groq',
                baseUrl: 'https://api.groq.com/openai/v1/chat/completions',
                headers: {
                    'content-type': 'application/json',
                }
            },
            perplexity: {
                name: 'Perplexity',
                baseUrl: 'https://api.perplexity.ai/chat/completions',
                headers: {
                    'content-type': 'application/json',
                }
            },
            gemini: {
                name: 'Gemini',
                baseUrl: 'https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent',
                headers: {
                    'content-type': 'application/json',
                }
            }
        };
    }

    async processWithAI(serviceId, text, userToken) {
        const service = this.services[serviceId];
        if (!service) {
            throw new Error(`ì§€ì›í•˜ì§€ ì•ŠëŠ” AI ì„œë¹„ìŠ¤: ${serviceId}`);
        }

        const prompt = this.createPrompt(text);

        try {
            let response;

            switch (serviceId) {
                case 'claude':
                    response = await this.callClaudeAPI(prompt, userToken);
                    break;
                case 'gpt':
                    response = await this.callGPTAPI(prompt, userToken);
                    break;
                case 'groq':
                    response = await this.callGroqAPI(prompt, userToken);
                    break;
                case 'perplexity':
                    response = await this.callPerplexityAPI(prompt, userToken);
                    break;
                case 'gemini':
                    response = await this.callGeminiAPI(prompt, userToken);
                    break;
                default:
                    throw new Error(`ì§€ì›í•˜ì§€ ì•ŠëŠ” AI ì„œë¹„ìŠ¤: ${serviceId}`);
            }

            return response;
        } catch (error) {
            console.error(`${service.name} API í˜¸ì¶œ ì˜¤ë¥˜:`, error);
            throw error;
        }
    }

    createPrompt(text) {
        return `ë‹¹ì‹ ì€ AI ìš”ì•½ ë„ìš°ë¯¸ì…ë‹ˆë‹¤.
ì•„ë˜ í…ìŠ¤íŠ¸ëŠ” ì‚¬ìš©ìê°€ ë§í•œ ìŒì„±ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•œ ê²ƒì…ë‹ˆë‹¤.
êµ¬ì–´ì²´ í‘œí˜„, ë§ë²„ë¦‡, ë°˜ë³µ, ë¬¸ì¥ ë¶€ì •í™•ì„± ë“±ì´ í¬í•¨ë˜ì–´ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
ì´ í…ìŠ¤íŠ¸ë¥¼ ì•„ë˜ ì¡°ê±´ì— ë§ê²Œ ì •ë¦¬í•˜ê³  ìš”ì•½í•´ ì£¼ì„¸ìš”:

1. í•µì‹¬ ë‚´ìš©ì„ ë†“ì¹˜ì§€ ë§ê³  ìµœëŒ€í•œ **ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ ìš”ì•½**í•´ ì£¼ì„¸ìš”.
2. **ë¶ˆí•„ìš”í•œ ë§ë²„ë¦‡**(ì˜ˆ: ìŒâ€¦, ì–´â€¦, ê·¸ëŸ¬ë‹ˆê¹Œâ€¦, ë­ë„ê¹Œâ€¦)ì€ ì œê±°í•´ ì£¼ì„¸ìš”.
3. ì˜ë¯¸ê°€ ì¤‘ë³µë˜ê±°ë‚˜, ë¶ˆëª…í™•í•œ ë¬¸ì¥ì€ **ë³´ì™„í•˜ê±°ë‚˜ ì‚­ì œ**í•´ ì£¼ì„¸ìš”.
4. ì¼ì •, í•  ì¼, ì •ë³´, ì£¼ìš” ì˜ê²¬ ë“±ì€ **ë¦¬ìŠ¤íŠ¸ í˜•ì‹**ìœ¼ë¡œ ì •ë¦¬í•´ ì£¼ì„¸ìš”.
5. ì „ì²´ ê²°ê³¼ëŠ” **Markdown í˜•ì‹**ìœ¼ë¡œ ì¶œë ¥í•´ ì£¼ì„¸ìš”.
6. **ìš”ì•½ë¬¸ì´ ì•„ë‹Œ "ì •ë¦¬ëœ ì›ë¬¸" ëŠë‚Œìœ¼ë¡œ ì¬êµ¬ì„±í•´ë„ ì¢‹ìŠµë‹ˆë‹¤.**

---
ğŸ—£ï¸ **ì‚¬ìš©ì ìŒì„± ì¸ì‹ í…ìŠ¤íŠ¸ ì›ë¬¸**:
"""
${text}
"""

ìœ„ í…ìŠ¤íŠ¸ë¥¼ ì¡°ê±´ì— ë§ê²Œ ì •ë¦¬í•´ì„œ Markdown í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•´ ì£¼ì„¸ìš”.`;
    }

    async callClaudeAPI(prompt, userToken) {
        const response = await fetch(this.services.claude.baseUrl, {
            method: 'POST',
            headers: {
                ...this.services.claude.headers,
                'x-api-key': userToken,
            },
            body: JSON.stringify({
                model: 'claude-3-sonnet-20240229',
                messages: [{ role: 'user', content: prompt }],
                max_tokens: 1024
            }),
        });

        if (!response.ok) {
            throw new Error(`Claude API ì˜¤ë¥˜: ${response.status}`);
        }

        const data = await response.json();
        return data?.content?.[0]?.text || 'ê²°ê³¼ë¥¼ ë°›ì•„ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.';
    }

    async callGPTAPI(prompt, userToken) {
        const response = await fetch(this.services.gpt.baseUrl, {
            method: 'POST',
            headers: {
                ...this.services.gpt.headers,
                'Authorization': `Bearer ${userToken}`,
            },
            body: JSON.stringify({
                model: 'gpt-3.5-turbo',
                messages: [{ role: 'user', content: prompt }],
                max_tokens: 1024
            }),
        });

        if (!response.ok) {
            throw new Error(`GPT API ì˜¤ë¥˜: ${response.status}`);
        }

        const data = await response.json();
        return data?.choices?.[0]?.message?.content || 'ê²°ê³¼ë¥¼ ë°›ì•„ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.';
    }

    async callGroqAPI(prompt, userToken) {
        const response = await fetch(this.services.groq.baseUrl, {
            method: 'POST',
            headers: {
                ...this.services.groq.headers,
                'Authorization': `Bearer ${userToken}`,
            },
            body: JSON.stringify({
                model: 'llama3-8b-8192',
                messages: [{ role: 'user', content: prompt }],
                max_tokens: 1024
            }),
        });

        if (!response.ok) {
            throw new Error(`Groq API ì˜¤ë¥˜: ${response.status}`);
        }

        const data = await response.json();
        return data?.choices?.[0]?.message?.content || 'ê²°ê³¼ë¥¼ ë°›ì•„ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.';
    }

    async callPerplexityAPI(prompt, userToken) {
        const response = await fetch(this.services.perplexity.baseUrl, {
            method: 'POST',
            headers: {
                ...this.services.perplexity.headers,
                'Authorization': `Bearer ${userToken}`,
            },
            body: JSON.stringify({
                model: 'llama-3.1-8b-instant',
                messages: [{ role: 'user', content: prompt }],
                max_tokens: 1024
            }),
        });

        if (!response.ok) {
            throw new Error(`Perplexity API ì˜¤ë¥˜: ${response.status}`);
        }

        const data = await response.json();
        return data?.choices?.[0]?.message?.content || 'ê²°ê³¼ë¥¼ ë°›ì•„ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.';
    }

    async callGeminiAPI(prompt, userToken) {
        const response = await fetch(`${this.services.gemini.baseUrl}?key=${userToken}`, {
            method: 'POST',
            headers: this.services.gemini.headers,
            body: JSON.stringify({
                contents: [{
                    parts: [{
                        text: prompt
                    }]
                }]
            }),
        });

        if (!response.ok) {
            throw new Error(`Gemini API ì˜¤ë¥˜: ${response.status}`);
        }

        const data = await response.json();
        return data?.candidates?.[0]?.content?.parts?.[0]?.text || 'ê²°ê³¼ë¥¼ ë°›ì•„ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.';
    }
}

const aiServiceManager = new AIServiceManager();
export default aiServiceManager;